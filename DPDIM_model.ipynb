{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTGA_4OIih_Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "drive.mount(‘/content/gdrive’)\n",
        "class DiffAug():\n",
        "    def __init__(self,\n",
        "                 strategy='color_crop_cutout_flip_scale_rotate',\n",
        "                 batch=False,\n",
        "                 ratio_cutout=0.5,\n",
        "                 single=False):\n",
        "        self.prob_flip = 0.5\n",
        "        self.ratio_scale = 1.2\n",
        "        self.ratio_rotate = 15.0\n",
        "        self.ratio_crop_pad = 0.125\n",
        "        self.ratio_cutout = ratio_cutout\n",
        "        self.ratio_noise = 0.05\n",
        "        self.brightness = 1.0\n",
        "        self.saturation = 2.0\n",
        "        self.contrast = 0.5\n",
        "\n",
        "        self.batch = batch\n",
        "\n",
        "        self.aug = True\n",
        "        if strategy == '' or strategy.lower() == 'none':\n",
        "            self.aug = False\n",
        "        else:\n",
        "            self.strategy = []\n",
        "            self.flip = False\n",
        "            self.color = False\n",
        "            self.cutout = False\n",
        "            for aug in strategy.lower().split('_'):\n",
        "                if aug == 'flip' and single == False:\n",
        "                    self.flip = True\n",
        "                elif aug == 'color' and single == False:\n",
        "                    self.color = True\n",
        "                elif aug == 'cutout' and single == False:\n",
        "                    self.cutout = True\n",
        "                else:\n",
        "                    self.strategy.append(aug)\n",
        "\n",
        "        self.aug_fn = {\n",
        "            'color': [self.brightness_fn, self.saturation_fn, self.contrast_fn],\n",
        "            'crop': [self.crop_fn],\n",
        "            'cutout': [self.cutout_fn],\n",
        "            'flip': [self.flip_fn],\n",
        "            'scale': [self.scale_fn],\n",
        "            'rotate': [self.rotate_fn],\n",
        "            'translate': [self.translate_fn],\n",
        "        }\n",
        "\n",
        "    def __call__(self, x, single_aug=True, seed=-1):\n",
        "        if not self.aug:\n",
        "            return x\n",
        "        else:\n",
        "            if self.flip:\n",
        "                self.set_seed(seed)\n",
        "                x = self.flip_fn(x, self.batch)\n",
        "            if self.color:\n",
        "                for f in self.aug_fn['color']:\n",
        "                    self.set_seed(seed)\n",
        "                    x = f(x, self.batch)\n",
        "            if len(self.strategy) > 0:\n",
        "                if single_aug:\n",
        "                    # single\n",
        "                    idx = np.random.randint(len(self.strategy))\n",
        "                    p = self.strategy[idx]\n",
        "                    for f in self.aug_fn[p]:\n",
        "                        self.set_seed(seed)\n",
        "                        x = f(x, self.batch)\n",
        "                else:\n",
        "                    # multiple\n",
        "                    for p in self.strategy:\n",
        "                        for f in self.aug_fn[p]:\n",
        "                            self.set_seed(seed)\n",
        "                            x = f(x, self.batch)\n",
        "            if self.cutout:\n",
        "                self.set_seed(seed)\n",
        "                x = self.cutout_fn(x, self.batch)\n",
        "\n",
        "            x = x.contiguous()\n",
        "            return x\n",
        "\n",
        "    def set_seed(self, seed):\n",
        "        if seed > 0:\n",
        "            np.random.seed(seed)\n",
        "            torch.random.manual_seed(seed)\n",
        "\n",
        "    def scale_fn(self, x, batch=True):\n",
        "        # x>1, max scale\n",
        "        # sx, sy: (0, +oo), 1: orignial size, 0.5: enlarge 2 times\n",
        "        ratio = self.ratio_scale\n",
        "\n",
        "        if batch:\n",
        "            sx = np.random.uniform() * (ratio - 1.0 / ratio) + 1.0 / ratio\n",
        "            sy = np.random.uniform() * (ratio - 1.0 / ratio) + 1.0 / ratio\n",
        "            theta = [[sx, 0, 0], [0, sy, 0]]\n",
        "            theta = torch.tensor(theta, dtype=torch.float, device=x.device)\n",
        "            theta = theta.expand(x.shape[0], 2, 3)\n",
        "        else:\n",
        "            sx = np.random.uniform(size=x.shape[0]) * (ratio - 1.0 / ratio) + 1.0 / ratio\n",
        "            sy = np.random.uniform(size=x.shape[0]) * (ratio - 1.0 / ratio) + 1.0 / ratio\n",
        "            theta = [[[sx[i], 0, 0], [0, sy[i], 0]] for i in range(x.shape[0])]\n",
        "            theta = torch.tensor(theta, dtype=torch.float, device=x.device)\n",
        "\n",
        "        grid = F.affine_grid(theta, x.shape)\n",
        "        x = F.grid_sample(x, grid)\n",
        "        return x\n",
        "\n",
        "    def rotate_fn(self, x, batch=True):\n",
        "        # [-180, 180], 90: anticlockwise 90 degree\n",
        "        ratio = self.ratio_rotate\n",
        "\n",
        "        if batch:\n",
        "            theta = (np.random.uniform() - 0.5) * 2 * ratio / 180 * float(np.pi)\n",
        "            theta = [[np.cos(theta), np.sin(-theta), 0], [np.sin(theta), np.cos(theta), 0]]\n",
        "            theta = torch.tensor(theta, dtype=torch.float, device=x.device)\n",
        "            theta = theta.expand(x.shape[0], 2, 3)\n",
        "        else:\n",
        "            theta = (np.random.uniform(size=x.shape[0]) - 0.5) * 2 * ratio / 180 * float(np.pi)\n",
        "            theta = [[[np.cos(theta[i]), np.sin(-theta[i]), 0],\n",
        "                      [np.sin(theta[i]), np.cos(theta[i]), 0]] for i in range(x.shape[0])]\n",
        "            theta = torch.tensor(theta, dtype=torch.float, device=x.device)\n",
        "\n",
        "        grid = F.affine_grid(theta, x.shape)\n",
        "        x = F.grid_sample(x, grid)\n",
        "        return x\n",
        "\n",
        "    def flip_fn(self, x, batch=True):\n",
        "        prob = self.prob_flip\n",
        "\n",
        "        if batch:\n",
        "            coin = np.random.uniform()\n",
        "            if coin < prob:\n",
        "                return x.flip(3)\n",
        "            else:\n",
        "                return x\n",
        "        else:\n",
        "            randf = torch.rand(x.size(0), 1, 1, 1, device=x.device)\n",
        "            return torch.where(randf < prob, x.flip(3), x)\n",
        "\n",
        "    def brightness_fn(self, x, batch=True):\n",
        "        # mean\n",
        "        ratio = self.brightness\n",
        "\n",
        "        if batch:\n",
        "            randb = np.random.uniform()\n",
        "        else:\n",
        "            randb = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
        "        x = x + (randb - 0.5) * ratio\n",
        "        return x\n",
        "\n",
        "    def saturation_fn(self, x, batch=True):\n",
        "        # channel concentration\n",
        "        ratio = self.saturation\n",
        "\n",
        "        x_mean = x.mean(dim=1, keepdim=True)\n",
        "        if batch:\n",
        "            rands = np.random.uniform()\n",
        "        else:\n",
        "            rands = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
        "        x = (x - x_mean) * (rands * ratio) + x_mean\n",
        "        return x\n",
        "\n",
        "    def contrast_fn(self, x, batch=True):\n",
        "        # spatially concentrating\n",
        "        ratio = self.contrast\n",
        "\n",
        "        x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "        if batch:\n",
        "            randc = np.random.uniform()\n",
        "        else:\n",
        "            randc = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
        "        x = (x - x_mean) * (randc + ratio) + x_mean\n",
        "        return x\n",
        "\n",
        "    def translate_fn(self, x, batch=True):\n",
        "        ratio = self.ratio_crop_pad\n",
        "\n",
        "        shift_y = int(x.size(3) * ratio + 0.5)\n",
        "        if batch:\n",
        "            translation_y = np.random.randint(-shift_y, shift_y + 1)\n",
        "        else:\n",
        "            translation_y = torch.randint(-shift_y,\n",
        "                                          shift_y + 1,\n",
        "                                          size=[x.size(0), 1, 1],\n",
        "                                          device=x.device)\n",
        "\n",
        "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "            torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "            torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "            torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "        )\n",
        "        grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "        x_pad = F.pad(x, (1, 1))\n",
        "        x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "        return x\n",
        "\n",
        "    def crop_fn(self, x, batch=True):\n",
        "        # The image is padded on its surrounding and then cropped.\n",
        "        ratio = self.ratio_crop_pad\n",
        "\n",
        "        shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "        if batch:\n",
        "            translation_x = np.random.randint(-shift_x, shift_x + 1)\n",
        "            translation_y = np.random.randint(-shift_y, shift_y + 1)\n",
        "        else:\n",
        "            translation_x = torch.randint(-shift_x,\n",
        "                                          shift_x + 1,\n",
        "                                          size=[x.size(0), 1, 1],\n",
        "                                          device=x.device)\n",
        "\n",
        "            translation_y = torch.randint(-shift_y,\n",
        "                                          shift_y + 1,\n",
        "                                          size=[x.size(0), 1, 1],\n",
        "                                          device=x.device)\n",
        "\n",
        "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "            torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "            torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "            torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "        )\n",
        "        grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "        grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "        x_pad = F.pad(x, (1, 1, 1, 1))\n",
        "        x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "        return x\n",
        "\n",
        "    def cutout_fn(self, x, batch=True):\n",
        "        ratio = self.ratio_cutout\n",
        "        cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "\n",
        "        if batch:\n",
        "            offset_x = np.random.randint(0, x.size(2) + (1 - cutout_size[0] % 2))\n",
        "            offset_y = np.random.randint(0, x.size(3) + (1 - cutout_size[1] % 2))\n",
        "        else:\n",
        "            offset_x = torch.randint(0,\n",
        "                                     x.size(2) + (1 - cutout_size[0] % 2),\n",
        "                                     size=[x.size(0), 1, 1],\n",
        "                                     device=x.device)\n",
        "\n",
        "            offset_y = torch.randint(0,\n",
        "                                     x.size(3) + (1 - cutout_size[1] % 2),\n",
        "                                     size=[x.size(0), 1, 1],\n",
        "                                     device=x.device)\n",
        "\n",
        "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "            torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "            torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "            torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "        )\n",
        "        grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "        grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "        mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "        mask[grid_batch, grid_x, grid_y] = 0\n",
        "        x = x * mask.unsqueeze(1)\n",
        "        return x\n",
        "\n",
        "    def cutout_inv_fn(self, x, batch=True):\n",
        "        ratio = self.ratio_cutout\n",
        "        cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "\n",
        "        if batch:\n",
        "            offset_x = np.random.randint(0, x.size(2) - cutout_size[0])\n",
        "            offset_y = np.random.randint(0, x.size(3) - cutout_size[1])\n",
        "        else:\n",
        "            offset_x = torch.randint(0,\n",
        "                                     x.size(2) - cutout_size[0],\n",
        "                                     size=[x.size(0), 1, 1],\n",
        "                                     device=x.device)\n",
        "            offset_y = torch.randint(0,\n",
        "                                     x.size(3) - cutout_size[1],\n",
        "                                     size=[x.size(0), 1, 1],\n",
        "                                     device=x.device)\n",
        "\n",
        "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "            torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "            torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "            torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "        )\n",
        "        grid_x = torch.clamp(grid_x + offset_x, min=0, max=x.size(2) - 1)\n",
        "        grid_y = torch.clamp(grid_y + offset_y, min=0, max=x.size(3) - 1)\n",
        "        mask = torch.zeros(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "        mask[grid_batch, grid_x, grid_y] = 1.\n",
        "        x = x * mask.unsqueeze(1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "__all__ = [\"Compose\", \"Lighting\", \"ColorJitter\"]\n",
        "\n",
        "\n",
        "def dist_l2(data, target):\n",
        "    dist = (data**2).sum(-1).unsqueeze(1) + (\n",
        "        target**2).sum(-1).unsqueeze(0) - 2 * torch.matmul(data, target.transpose(1, 0))\n",
        "    return dist\n",
        "\n",
        "\n",
        "def get_time():\n",
        "    return str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    def __init__(self, fpath=None):\n",
        "        self.console = sys.stdout\n",
        "        self.file = None\n",
        "        if fpath is not None:\n",
        "            self.file = open(fpath, 'w')\n",
        "\n",
        "    def __del__(self):\n",
        "        self.close()\n",
        "\n",
        "    def __enter__(self):\n",
        "        pass\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self.close()\n",
        "\n",
        "    def write(self, msg):\n",
        "        self.console.write(msg)\n",
        "        if self.file is not None:\n",
        "            self.file.write(msg)\n",
        "\n",
        "    def flush(self):\n",
        "        self.console.flush()\n",
        "        if self.file is not None:\n",
        "            self.file.flush()\n",
        "            os.fsync(self.file.fileno())\n",
        "\n",
        "    def close(self):\n",
        "        self.console.close()\n",
        "        if self.file is not None:\n",
        "            self.file.close()\n",
        "\n",
        "\n",
        "class TimeStamp():\n",
        "    def __init__(self, print_log=True):\n",
        "        self.prev = time.time()\n",
        "        self.print_log = print_log\n",
        "        self.times = {}\n",
        "\n",
        "    def set(self):\n",
        "        self.prev = time.time()\n",
        "\n",
        "    def flush(self):\n",
        "        if self.print_log:\n",
        "            print(\"\\n=========Summary=========\")\n",
        "            for key in self.times.keys():\n",
        "                times = np.array(self.times[key])\n",
        "                print(\n",
        "                    f\"{key}: {times.sum():.4f}s (avg {times.mean():.4f}s, std {times.std():.4f}, count {len(times)})\"\n",
        "                )\n",
        "                self.times[key] = []\n",
        "\n",
        "    def stamp(self, name=''):\n",
        "        if self.print_log:\n",
        "            spent = time.time() - self.prev\n",
        "            # print(f\"{name}: {spent:.4f}s\")\n",
        "            if name in self.times.keys():\n",
        "                self.times[name].append(spent)\n",
        "            else:\n",
        "                self.times[name] = [spent]\n",
        "            self.set()\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1, )):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "\n",
        "    return res\n",
        "\n",
        "def Eval_auc(output, target):\n",
        "    avg_tpr, avg_fpr, avg_auc, img_num = 0.0, 0.0, 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        for pred, gt in output:\n",
        "            if self.colabcuda:\n",
        "                pred = trans(pred).colabcuda()\n",
        "                #index = torch.arange(n).to(device)\n",
        "                pred = (pred - torch.min(pred)) / (torch.max(pred) -\n",
        "                                                    torch.min(pred) + 1e-20)\n",
        "                gt = trans(gt).colabcuda()\n",
        "            else:\n",
        "                pred = trans(pred)\n",
        "                pred = (pred - torch.min(pred)) / (torch.max(pred) -\n",
        "                                                    torch.min(pred) + 1e-20)\n",
        "                gt = trans(gt)\n",
        "            TPR, FPR = self._eval_roc(pred, gt, 255)\n",
        "            avg_tpr += TPR\n",
        "            avg_fpr += FPR\n",
        "            # img_num += 1.0\n",
        "        avg_tpr = avg_tpr / img_num\n",
        "        avg_fpr = avg_fpr / img_num\n",
        "\n",
        "        sorted_idxes = torch.argsort(avg_fpr)\n",
        "        avg_tpr = avg_tpr[sorted_idxes]\n",
        "        avg_fpr = avg_fpr[sorted_idxes]\n",
        "        avg_auc = torch.trapz(avg_tpr, avg_fpr)\n",
        "\n",
        "        return avg_auc.item(), avg_tpr, avg_fpr\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "class Plotter():\n",
        "    def __init__(self, path, nepoch, idx=0):\n",
        "        self.path = path\n",
        "        self.data = {'epoch': [], 'acc_tr': [], 'acc_val': [], 'loss_tr': [], 'loss_val': []}\n",
        "        self.nepoch = nepoch\n",
        "        self.plot_freq = 10\n",
        "        self.idx = idx\n",
        "\n",
        "    def update(self, epoch, acc_tr, acc_val, loss_tr, loss_val):\n",
        "        self.data['epoch'].append(epoch)\n",
        "        self.data['acc_tr'].append(acc_tr)\n",
        "        self.data['acc_val'].append(acc_val)\n",
        "        self.data['loss_tr'].append(loss_tr)\n",
        "        self.data['loss_val'].append(loss_val)\n",
        "\n",
        "        if len(self.data['epoch']) % self.plot_freq == 0:\n",
        "            self.plot()\n",
        "\n",
        "    def plot(self, color='black'):\n",
        "        fig, axes = plt.subplots(1, 4, figsize=(4 * 4, 3))\n",
        "        fig.tight_layout(h_pad=3, w_pad=3)\n",
        "\n",
        "        fig.suptitle(f\"{self.path}\", size=16, y=1.1)\n",
        "\n",
        "        axes[0].plot(self.data['epoch'], self.data['acc_tr'], color, lw=0.8)\n",
        "        axes[0].set_xlim([0, self.nepoch])\n",
        "        axes[0].set_ylim([0, 100])\n",
        "        axes[0].set_title('acc train')\n",
        "\n",
        "        axes[1].plot(self.data['epoch'], self.data['acc_val'], color, lw=0.8)\n",
        "        axes[1].set_xlim([0, self.nepoch])\n",
        "        axes[1].set_ylim([0, 100])\n",
        "        axes[1].set_title('acc val')\n",
        "\n",
        "        axes[2].plot(self.data['epoch'], self.data['loss_tr'], color, lw=0.8)\n",
        "        axes[2].set_xlim([0, self.nepoch])\n",
        "        axes[2].set_ylim([0, 3])\n",
        "        axes[2].set_title('loss train')\n",
        "\n",
        "        axes[3].plot(self.data['epoch'], self.data['loss_val'], color, lw=0.8)\n",
        "        axes[3].set_xlim([0, self.nepoch])\n",
        "        axes[3].set_ylim([0, 3])\n",
        "        axes[3].set_title('loss val')\n",
        "\n",
        "        for ax in axes:\n",
        "            ax.set_xlabel('epochs')\n",
        "\n",
        "        plt.savefig(f'{self.path}/curve_{self.idx}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def random_indices(y, nclass=2, intraclass=False, device='cuda'):               #10\n",
        "    n = len(y)\n",
        "    if intraclass:\n",
        "        index = torch.arange(n).to(device)\n",
        "        for c in range(nclass):\n",
        "            index_c = index[y == c]\n",
        "            if len(index_c) > 0:\n",
        "                randidx = torch.randperm(len(index_c))\n",
        "                index[y == c] = index_c[randidx]\n",
        "    else:\n",
        "        index = torch.randperm(n).to(device)\n",
        "    return index\n",
        "\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img):\n",
        "        for t in self.transforms:\n",
        "            img = t(img)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        format_string = self.__class__.__name__ + '('\n",
        "        for t in self.transforms:\n",
        "            format_string += '\\n'\n",
        "            format_string += '    {0}'.format(t)\n",
        "        format_string += '\\n)'\n",
        "        return format_string\n",
        "\n",
        "\n",
        "class Lighting(object):\n",
        "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
        "    def __init__(self, alphastd, eigval, eigvec, device='cpu'):\n",
        "        self.alphastd = alphastd\n",
        "        self.eigval = torch.tensor(eigval, device=device)\n",
        "        self.eigvec = torch.tensor(eigvec, device=device)\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if self.alphastd == 0:\n",
        "            return img\n",
        "\n",
        "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
        "        rgb = self.eigvec.type_as(img).clone() \\\n",
        "            .mul(alpha.view(1, 3).expand(3, 3)) \\\n",
        "            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n",
        "            .sum(1).squeeze()\n",
        "\n",
        "        # make differentiable\n",
        "        if len(img.shape) == 4:\n",
        "            return img + rgb.view(1, 3, 1, 1).expand_as(img)\n",
        "        else:\n",
        "            return img + rgb.view(3, 1, 1).expand_as(img)\n",
        "\n",
        "\n",
        "class Grayscale(object):\n",
        "    def __call__(self, img):\n",
        "        gs = img.clone()\n",
        "        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n",
        "        gs[1].copy_(gs[0])\n",
        "        gs[2].copy_(gs[0])\n",
        "        return gs\n",
        "\n",
        "\n",
        "class Saturation(object):\n",
        "    def __init__(self, var):\n",
        "        self.var = var\n",
        "\n",
        "    def __call__(self, img):\n",
        "        gs = Grayscale()(img)\n",
        "        alpha = random.uniform(-self.var, self.var)\n",
        "        return img.lerp(gs, alpha)\n",
        "\n",
        "\n",
        "class Brightness(object):\n",
        "    def __init__(self, var):\n",
        "        self.var = var\n",
        "\n",
        "    def __call__(self, img):\n",
        "        gs = img.new().resize_as_(img).zero_()\n",
        "        alpha = random.uniform(-self.var, self.var)\n",
        "        return img.lerp(gs, alpha)\n",
        "\n",
        "\n",
        "class Contrast(object):\n",
        "    def __init__(self, var):\n",
        "        self.var = var\n",
        "\n",
        "    def __call__(self, img):\n",
        "        gs = Grayscale()(img)\n",
        "        gs.fill_(gs.mean())\n",
        "        alpha = random.uniform(-self.var, self.var)\n",
        "        return img.lerp(gs, alpha)\n",
        "\n",
        "\n",
        "class ColorJitter(object):\n",
        "    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n",
        "        self.brightness = brightness\n",
        "        self.contrast = contrast\n",
        "        self.saturation = saturation\n",
        "\n",
        "    def __call__(self, img):\n",
        "        self.transforms = []\n",
        "        if self.brightness != 0:\n",
        "            self.transforms.append(Brightness(self.brightness))\n",
        "        if self.contrast != 0:\n",
        "            self.transforms.append(Contrast(self.contrast))\n",
        "        if self.saturation != 0:\n",
        "            self.transforms.append(Saturation(self.saturation))\n",
        "\n",
        "        random.shuffle(self.transforms)\n",
        "        transform = Compose(self.transforms)\n",
        "        # print(transform)\n",
        "        return transform(img)\n",
        "\n",
        "\n",
        "class CutOut():\n",
        "    def __init__(self, ratio, device='cpu'):\n",
        "        self.ratio = ratio\n",
        "        self.device = device\n",
        "\n",
        "    def __call__(self, x):\n",
        "        n, _, h, w = x.shape\n",
        "        cutout_size = [int(h * self.ratio + 0.5), int(w * self.ratio + 0.5)]\n",
        "        offset_x = torch.randint(h + (1 - cutout_size[0] % 2), size=[1], device=self.device)[0]\n",
        "        offset_y = torch.randint(w + (1 - cutout_size[1] % 2), size=[1], device=self.device)[0]\n",
        "\n",
        "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "            torch.arange(n, dtype=torch.long, device=self.device),\n",
        "            torch.arange(cutout_size[0], dtype=torch.long, device=self.device),\n",
        "            torch.arange(cutout_size[1], dtype=torch.long, device=self.device),\n",
        "        )\n",
        "        grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=h - 1)\n",
        "        grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=w - 1)\n",
        "        mask = torch.ones(n, h, w, dtype=x.dtype, device=self.device)\n",
        "        mask[grid_batch, grid_x, grid_y] = 0\n",
        "\n",
        "        x = x * mask.unsqueeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Normalize():\n",
        "    def __init__(self, mean, std, device='cpu'):\n",
        "        self.mean = torch.tensor(mean, device=device).reshape(1, len(mean), 1, 1)\n",
        "        self.std = torch.tensor(std, device=device).reshape(1, len(mean), 1, 1)\n",
        "\n",
        "    def __call__(self, x, seed=-1):\n",
        "        return (x - self.mean) / self.std"
      ],
      "metadata": {
        "id": "-MSkfiEMinDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convnet.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 net_norm='instance',\n",
        "                 net_depth=3,\n",
        "                 net_width=128,\n",
        "                 channel=3,\n",
        "                 net_act='relu',\n",
        "                 net_pooling='avgpooling',\n",
        "                 im_size=(32, 32)):\n",
        "        # print(f\"Define Convnet (depth {net_depth}, width {net_width}, norm {net_norm})\")\n",
        "        super(ConvNet, self).__init__()\n",
        "        if net_act == 'sigmoid':\n",
        "            self.net_act = nn.Sigmoid()\n",
        "        elif net_act == 'relu':\n",
        "            self.net_act = nn.ReLU()\n",
        "        elif net_act == 'leakyrelu':\n",
        "            self.net_act = nn.LeakyReLU(negative_slope=0.01)\n",
        "        else:\n",
        "            exit('unknown activation function: %s' % net_act)\n",
        "\n",
        "        if net_pooling == 'maxpooling':\n",
        "            self.net_pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        elif net_pooling == 'avgpooling':\n",
        "            self.net_pooling = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        elif net_pooling == 'none':\n",
        "            self.net_pooling = None\n",
        "        else:\n",
        "            exit('unknown net_pooling: %s' % net_pooling)\n",
        "\n",
        "        self.depth = net_depth\n",
        "        self.net_norm = net_norm\n",
        "\n",
        "        self.layers, shape_feat = self._make_layers(channel, net_width, net_depth, net_norm,\n",
        "                                                    net_pooling, im_size)\n",
        "        num_feat = shape_feat[0] * shape_feat[1] * shape_feat[2]\n",
        "        self.classifier = nn.Linear(num_feat, num_classes)\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        for d in range(self.depth):\n",
        "            x = self.layers['conv'][d](x)\n",
        "            if len(self.layers['norm']) > 0:\n",
        "                x = self.layers['norm'][d](x)\n",
        "            x = self.layers['act'][d](x)\n",
        "            if len(self.layers['pool']) > 0:\n",
        "                x = self.layers['pool'][d](x)\n",
        "\n",
        "        # x = nn.functional.avg_pool2d(x, x.shape[-1])\n",
        "        out = x.view(x.shape[0], -1)\n",
        "        logit = self.classifier(out)\n",
        "\n",
        "        if return_features:\n",
        "            return logit, out\n",
        "        else:\n",
        "            return logit\n",
        "\n",
        "    def get_feature(self, x, idx_from, idx_to=-1, return_prob=False, return_logit=False):\n",
        "        if idx_to == -1:\n",
        "            idx_to = idx_from\n",
        "        features = []\n",
        "\n",
        "        for d in range(self.depth):\n",
        "            x = self.layers['conv'][d](x)\n",
        "            if self.net_norm:\n",
        "                x = self.layers['norm'][d](x)\n",
        "            x = self.layers['act'][d](x)\n",
        "            if self.net_pooling:\n",
        "                x = self.layers['pool'][d](x)\n",
        "            features.append(x)\n",
        "            if idx_to < len(features):\n",
        "                return features[idx_from:idx_to + 1]\n",
        "\n",
        "        if return_prob:\n",
        "            out = x.view(x.size(0), -1)\n",
        "            logit = self.classifier(out)\n",
        "            prob = torch.softmax(logit, dim=-1)\n",
        "            return features, prob\n",
        "        elif return_logit:\n",
        "            out = x.view(x.size(0), -1)\n",
        "            logit = self.classifier(out)\n",
        "            return features, logit\n",
        "        else:\n",
        "            return features[idx_from:idx_to + 1]\n",
        "\n",
        "    def _get_normlayer(self, net_norm, shape_feat):\n",
        "        # shape_feat = (c * h * w)\n",
        "        if net_norm == 'batch':\n",
        "            norm = nn.BatchNorm2d(shape_feat[0], affine=True)\n",
        "        elif net_norm == 'layer':\n",
        "            norm = nn.LayerNorm(shape_feat, elementwise_affine=True)\n",
        "        elif net_norm == 'instance':\n",
        "            norm = nn.GroupNorm(shape_feat[0], shape_feat[0], affine=True)\n",
        "        elif net_norm == 'group':\n",
        "            norm = nn.GroupNorm(4, shape_feat[0], affine=True)\n",
        "        elif net_norm == 'none':\n",
        "            norm = None\n",
        "        else:\n",
        "            norm = None\n",
        "            exit('unknown net_norm: %s' % net_norm)\n",
        "        return norm\n",
        "\n",
        "    def _make_layers(self, channel, net_width, net_depth, net_norm, net_pooling, im_size):\n",
        "        layers = {'conv': [], 'norm': [], 'act': [], 'pool': []}\n",
        "\n",
        "        in_channels = channel\n",
        "        if im_size[0] == 28:\n",
        "            im_size = (32, 32)\n",
        "        shape_feat = [in_channels, im_size[0], im_size[1]]\n",
        "\n",
        "        for d in range(net_depth):\n",
        "            layers['conv'] += [\n",
        "                nn.Conv2d(in_channels,\n",
        "                          net_width,\n",
        "                          kernel_size=3,\n",
        "                          padding=3 if channel == 1 and d == 0 else 1)\n",
        "            ]\n",
        "            shape_feat[0] = net_width\n",
        "            if net_norm != 'none':\n",
        "                layers['norm'] += [self._get_normlayer(net_norm, shape_feat)]\n",
        "            layers['act'] += [self.net_act]\n",
        "            in_channels = net_width\n",
        "            if net_pooling != 'none':\n",
        "                layers['pool'] += [self.net_pooling]\n",
        "                shape_feat[1] //= 2\n",
        "                shape_feat[2] //= 2\n",
        "\n",
        "        layers['conv'] = nn.ModuleList(layers['conv'])\n",
        "        layers['norm'] = nn.ModuleList(layers['norm'])\n",
        "        layers['act'] = nn.ModuleList(layers['act'])\n",
        "        layers['pool'] = nn.ModuleList(layers['pool'])\n",
        "        layers = nn.ModuleDict(layers)\n",
        "\n",
        "        return layers, shape_feat"
      ],
      "metadata": {
        "id": "cx11UUWRi0Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=4, stride=4, padding=0)\n",
        "        self.fc1 = nn.Linear(196, 1)\n",
        "        self.fc = nn.Linear(196, 2)\n",
        "\n",
        "    def forward(self, x, print_size=False): #edit\n",
        "\n",
        "        x = nn.Conv2d(3, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, size, size])\n",
        "        x = nn.LeakyReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=2, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, size // 2, size // 2])\n",
        "        x = nn.LeakyReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, size // 2, size // 2])\n",
        "        x = nn.LeakyReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=2, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, size // 4, size // 4])\n",
        "        x = nn.LeakyReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, size // 4, size // 4])\n",
        "        x = nn.LeakyReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, size // 4, size // 4])\n",
        "        x = nn.LeakyReLU()\n",
        "\n",
        "        # if print_size:\n",
        "        #     print(x.size())\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=2, padding=1)\n",
        "        x = nn.LayerNorm(normalized_shape=[196, 4, 4])\n",
        "        x = nn.LeakyReLU()\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # if print_size:\n",
        "        #     print(x.size())\n",
        "        fc1 = self.fc1(x)#source\n",
        "        fc = self.fc(x)#class\n",
        "\n",
        "        return fc1,fc\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        def noise_function(x):\n",
        "          return torch.randn(64, x.view(x.size(0), -1))\n",
        "        self.batch_size=64\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, print_size=False):\n",
        "\n",
        "        x = nn.Linear(100, 196*4*4)\n",
        "        x = nn.ReLU(nn.BatchNorm1d(196*4*4))\n",
        "        x = x.view(-1, 196, 4, 4)\n",
        "        x = nn.ConvTranspose2d(196, 196, kernel_size=4, stride=2, padding=1)\n",
        "        x = nn.BatchNorm2d(196)\n",
        "        x = nn.ReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.BatchNorm2d(196)\n",
        "        x = nn.ReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.BatchNorm2d(196)\n",
        "        x = nn.ReLU()\n",
        "        x = nn.Conv2d(196, 196, kernel_size=3, stride=1, padding=1)\n",
        "        x = nn.BatchNorm2d(196)\n",
        "        x = nn.ReLU()\n",
        "        x = nn.ConvTranspose2d(196, 196, kernel_size=4, stride=2, padding=1)\n",
        "        x = nn.BatchNorm2d(196)\n",
        "        x = nn.ReLU()\n",
        "        x = nn.deconv2d(x, [self.batch_size, 196, 3, self.noise_function(x)])\n",
        "        # bn is not applied\n",
        "        x = self.tanh(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "0MJPIkQ0it6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ipc=50\n",
        "batch_size=64\n",
        "epochs=100\n",
        "epochs_eval=1000\n",
        "epochs_match=100\n",
        "epochs_match_train=16\n",
        "lr=5e-6\n",
        "eval_lr=0.01\n",
        "momentum=0.9\n",
        "weight_decay=5e-4\n",
        "match_coeff=0.001\n",
        "match_model='convnet'\n",
        "matchs='feat'\n",
        "eval_model=['convnet']\n",
        "dim_noise=100\n",
        "num_workers=4\n",
        "print_freq=50\n",
        "eval_interval=10\n",
        "test_interval=200\n",
        "fix_disc=False\n",
        "\n",
        "data='cifar10'\n",
        "num-classes=2\n",
        "data-dir='./data'\n",
        "output-dir='./results/'\n",
        "logs-dir='./logs/'\n",
        "weight='./weight/'\n",
        "match_aug=False\n",
        "aug_type='color_crop_cutout'\n",
        "mixup_net='cut'\n",
        "metric='l1'\n",
        "bias=False\n",
        "fc=False\n",
        "mix_p=-1.0\n",
        "beta=1.0\n",
        "tag='test'\n",
        "seed=3407"
      ],
      "metadata": {
        "id": "1bFmYsRujUl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import colab\n",
        "from colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "import models.resnet as RN\n",
        "import models.convnet as CN\n",
        "import models.resnet_ap as RNAP\n",
        "import models.densenet_cifar as DN\n",
        "from gan_model import Generator, Discriminator\n",
        "from utils import AverageMeter, accuracy, Normalize, Logger, rand_bbox\n",
        "from augment import DiffAug\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def str2bool(v):\n",
        "    \"\"\"Cast string to boolean\n",
        "    \"\"\"\n",
        "    if isinstance(v, bool):\n",
        "        return v\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "def transformation(pth):\n",
        "  data_transforms= transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "  dt=datasets.ImageFolder(pth,transform=data_transforms)\n",
        "  return dt\n",
        "\n",
        "def load_data():\n",
        "  img_dt='/content/drive/MyDrive/Projects/astar/isic'#'/content/drive/MyDrive/Projects/astar/32x32'\n",
        "  img_dt2='/content/drive/MyDrive/Projects/astar/isic2'\n",
        "  exl='/content/drive/MyDrive/Projects/astar/ISBI2016_GroundTruth.csv'\n",
        "  trainset=transformation(drive.mount(img_dt))\n",
        "  testset=transformation(drive.mount(img_dt2))\n",
        "  trainloader = torch.utils.data.DataLoader(\n",
        "      trainset, batch_size=batch_size, shuffle=True,\n",
        "      num_workers=num_workers, drop_last=True\n",
        "  )\n",
        "  testloader = torch.utils.data.DataLoader(\n",
        "      testset, batch_size=batch_size, shuffle=False,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  return trainloader, testloader\n",
        "\n",
        "\n",
        "def define_model(num_classes, e_model=None):\n",
        "    '''Obtain model for training, validating and matching\n",
        "    With no 'e_model' specified, it returns a random model\n",
        "    '''\n",
        "    if e_model:\n",
        "        model = e_model\n",
        "    else:\n",
        "        model_pool = ['convnet', 'resnet10', 'resnet18',\n",
        "                      'resnet10_ap', 'resnet18_ap']\n",
        "        model = random.choice(model_pool)\n",
        "        print('Random model: {}'.format(model))\n",
        "\n",
        "    if data == 'mnist' or data == 'fashion':\n",
        "        nch = 1\n",
        "    else:\n",
        "        nch = 3\n",
        "\n",
        "    if model == 'convnet':\n",
        "        return CN.ConvNet(num_classes, channel=nch)\n",
        "    # elif model == 'resnet10':\n",
        "    #     return RN.ResNet(data, 10, num_classes, nch=nch)\n",
        "    # elif model == 'resnet18':\n",
        "    #     return RN.ResNet(data, 18, num_classes, nch=nch)\n",
        "    # elif model == 'resnet34':\n",
        "    #     return RN.ResNet(data, 34, num_classes, nch=nch)\n",
        "    # elif model == 'resnet50':\n",
        "    #     return RN.ResNet(data, 50, num_classes, nch=nch)\n",
        "    # elif model == 'resnet101':\n",
        "    #     return RN.ResNet(data, 101, num_classes, nch=nch)\n",
        "    # elif model == 'resnet10_ap':\n",
        "    #     return RNAP.ResNetAP(data, 10, num_classes, nch=nch)\n",
        "    # elif model == 'resnet18_ap':\n",
        "    #     return RNAP.ResNetAP(data, 18, num_classes, nch=nch)\n",
        "    # elif model == 'resnet34_ap':\n",
        "    #     return RNAP.ResNetAP(data, 34, num_classes, nch=nch)\n",
        "    # elif model == 'resnet50_ap':\n",
        "    #     return RNAP.ResNetAP(data, 50, num_classes, nch=nch)\n",
        "    # elif model == 'resnet101_ap':\n",
        "    #     return RNAP.ResNetAP(data, 101, num_classes, nch=nch)\n",
        "    # elif model == 'densenet':\n",
        "    #     return DN.densenet_cifar(num_classes)\n",
        "\n",
        "\n",
        "def calc_gradient_penalty(discriminator, img_real, img_syn):\n",
        "    ''' Gradient penalty from Wasserstein GAN\n",
        "    '''\n",
        "    LAMBDA = 10\n",
        "    n_size = img_real.shape[-1]\n",
        "    batch_size = img_real.shape[0]\n",
        "    n_channels = img_real.shape[1]\n",
        "\n",
        "    alpha = torch.rand(batch_size, 1)\n",
        "    alpha = alpha.expand(batch_size, int(img_real.nelement() / batch_size)).contiguous()\n",
        "    alpha = alpha.view(batch_size, n_channels, n_size, n_size)\n",
        "    alpha = alpha.colabcuda()\n",
        "\n",
        "    img_syn = img_syn.view(batch_size, n_channels, n_size, n_size)\n",
        "    interpolates = alpha * img_real.detach() + ((1 - alpha) * img_syn.detach())\n",
        "\n",
        "    interpolates = interpolates.colabcuda()\n",
        "    interpolates.requires_grad_(True)\n",
        "\n",
        "    disc_interpolates, _ = discriminator(interpolates)\n",
        "\n",
        "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                    grad_outputs=torch.ones(disc_interpolates.size()).colabcuda(),\n",
        "                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "def dist(x, y, method='mse'):\n",
        "    \"\"\"Distance objectives\n",
        "    \"\"\"\n",
        "    if method == 'mse':\n",
        "        dist_ = (x - y).pow(2).sum()\n",
        "    elif method == 'l1':\n",
        "        dist_ = (x - y).abs().sum()\n",
        "    elif method == 'l1_mean':\n",
        "        n_b = x.shape[0]\n",
        "        dist_ = (x - y).abs().reshape(n_b, -1).mean(-1).sum()\n",
        "    elif method == 'cos':\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        y = y.reshape(y.shape[0], -1)\n",
        "        dist_ = torch.sum(1 - torch.sum(x * y, dim=-1) /\n",
        "                          (torch.norm(x, dim=-1) * torch.norm(y, dim=-1) + 1e-6))\n",
        "\n",
        "    return dist_\n",
        "\n",
        "\n",
        "def add_loss(loss_sum, loss):\n",
        "    if loss_sum == None:\n",
        "        return loss\n",
        "    else:\n",
        "        return loss_sum + loss\n",
        "\n",
        "\n",
        "def matchloss(img_real, img_syn, lab_real, lab_syn, model):\n",
        "    \"\"\"Matching losses (feature or gradient)\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "\n",
        "    if 'feat' in matchs:\n",
        "        with torch.no_grad():\n",
        "            feat_tg = model.get_feature(img_real, idx_from, idx_to)\n",
        "        feat = model.get_feature(img_syn, idx_from, idx_to)\n",
        "\n",
        "        for i in range(len(feat)):\n",
        "            loss = add_loss(loss, dist(feat_tg[i].mean(0), feat[i].mean(0), method=metric) * 0.001)\n",
        "\n",
        "    elif 'grad' in matchs:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        output_real = model(img_real)\n",
        "        loss_real = criterion(output_real, lab_real)\n",
        "        g_real = torch.autograd.grad(loss_real, model.parameters())\n",
        "        g_real = list((g.detach() for g in g_real))\n",
        "\n",
        "        output_syn = model(img_syn)\n",
        "        loss_syn = criterion(output_syn, lab_syn)\n",
        "        g_syn = torch.autograd.grad(loss_syn, model.parameters(), create_graph=True)\n",
        "\n",
        "        for i in range(len(g_real)):\n",
        "            if (len(g_real[i].shape) == 1) and not bias:  # bias, normliazation\n",
        "                continue\n",
        "            if (len(g_real[i].shape) == 2) and not fc:\n",
        "                continue\n",
        "\n",
        "            loss = add_loss(loss, dist(g_real[i], g_syn[i], method=metric) * 0.001)\n",
        "\n",
        "    elif 'logit' in matchs:\n",
        "        output_real = F.log_softmax(model(img_real), dim=1)\n",
        "        output_syn = F.log_softmax(model(img_syn), dim=1)\n",
        "        loss = add_loss(loss, ((output_real - output_syn) ** 2).mean() * 0.01)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def remove_aug(augtype, remove_aug):\n",
        "    aug_list = []\n",
        "    for aug in augtype.split(\"_\"):\n",
        "        if aug not in remove_aug.split(\"_\"):\n",
        "            aug_list.append(aug)\n",
        "\n",
        "    return \"_\".join(aug_list)\n",
        "\n",
        "\n",
        "def diffaug(device='cuda'):\n",
        "    \"\"\"Differentiable augmentation for condensation\n",
        "    \"\"\"\n",
        "    aug_type = aug_type\n",
        "    if data == 'cifar10':\n",
        "        normalize = Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201), device='cuda')\n",
        "    elif data == 'svhn':\n",
        "        normalize = Normalize((0.437, 0.444, 0.473), (0.198, 0.201, 0.197), device='cuda')\n",
        "    elif data == 'fashion':\n",
        "        normalize = Normalize((0.286,), (0.353,), device='cuda')\n",
        "    elif data == 'mnist':\n",
        "        normalize = Normalize((0.131,), (0.308,), device='cuda')\n",
        "    print(\"Augmentataion Matching: \", aug_type)\n",
        "    augment = DiffAug(strategy=aug_type, batch=True)\n",
        "    aug_batch = transforms.Compose([normalize, augment])\n",
        "\n",
        "    if mixup_net == 'cut':\n",
        "        aug_type = remove_aug(aug_type, 'cutout')\n",
        "    print(\"Augmentataion Net update: \", aug_type)\n",
        "    augment_rand = DiffAug(strategy=aug_type, batch=False)\n",
        "    aug_rand = transforms.Compose([normalize, augment_rand])\n",
        "\n",
        "    return aug_batch, aug_rand\n",
        "\n",
        "\n",
        "def train(epoch, generator, discriminator, optim_g, optim_d, trainloader, criterion, aug, aug_rand):\n",
        "    '''The main training function for the generator\n",
        "    '''\n",
        "    generator.train()\n",
        "    gen_losses = AverageMeter()\n",
        "    disc_losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    model = define_model( num_classes).colabcuda()\n",
        "    model.train()\n",
        "    optim_model = torch.optim.SGD(model.parameters(), eval_lr, momentum=momentum,\n",
        "                                  weight_decay=weight_decay)\n",
        "\n",
        "    for batch_idx, (img_real, lab_real) in enumerate(trainloader):\n",
        "        img_real = img_real.colabcuda()\n",
        "        lab_real = lab_real.colabcuda()\n",
        "\n",
        "        # train the generator\n",
        "        discriminator.eval()\n",
        "        optim_g.zero_grad()\n",
        "\n",
        "        # obtain the noise with one-hot class labels\n",
        "        noise = torch.normal(0, 1, (batch_size, dim_noise))\n",
        "        lab_onehot = torch.zeros((batch_size, num_classes))\n",
        "        lab_onehot[torch.arange(batch_size), lab_real] = 1\n",
        "        noise[torch.arange(batch_size), :num_classes] = lab_onehot[torch.arange(batch_size)]\n",
        "        noise = noise.colabcuda()\n",
        "\n",
        "        img_syn = generator(noise)\n",
        "        gen_source, gen_class = discriminator(img_syn)\n",
        "        gen_source = gen_source.mean()\n",
        "        gen_class = criterion(gen_class, lab_real)\n",
        "\n",
        "        gen_loss = - gen_source + gen_class\n",
        "\n",
        "        # update the match model to obtain more various matching signals\n",
        "        train_match_model( model, optim_model, trainloader, criterion, aug_rand)\n",
        "        # calculate the matching loss\n",
        "        if match_aug:\n",
        "            img_aug = aug(torch.cat([img_real, img_syn]))\n",
        "            match_loss = matchloss( img_aug[:batch_size], img_aug[batch_size:], lab_real, lab_real, model)# * match_coeff\n",
        "        else:\n",
        "            match_loss = matchloss( img_real, img_syn, lab_real, lab_real, model)# * match_coeff\n",
        "        gen_loss = gen_loss + match_loss\n",
        "\n",
        "        gen_loss.backward()\n",
        "        optim_g.step()\n",
        "\n",
        "        # train the discriminator\n",
        "        discriminator.train()\n",
        "        optim_d.zero_grad()\n",
        "        lab_syn = torch.randint(num_classes, (batch_size,))\n",
        "        noise = torch.normal(0, 1, (batch_size, dim_noise))\n",
        "        lab_onehot = torch.zeros((batch_size, num_classes))\n",
        "        lab_onehot[torch.arange(batch_size), lab_syn] = 1\n",
        "        noise[torch.arange(batch_size), :num_classes] = lab_onehot[torch.arange(batch_size)]\n",
        "        noise = noise.colabcuda()\n",
        "        lab_syn = lab_syn.colabcuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            img_syn = generator(noise)\n",
        "\n",
        "        disc_fake_source, disc_fake_class = discriminator(img_syn)\n",
        "        disc_fake_source = disc_fake_source.mean()\n",
        "        disc_fake_class = criterion(disc_fake_class, lab_syn)\n",
        "\n",
        "        disc_real_source, disc_real_class = discriminator(img_real)\n",
        "        acc1, acc5 = accuracy(disc_real_class.data, lab_real, topk=(1, 5))\n",
        "        auc = Eval_AUC(disc_real_class.data, lab_real)\n",
        "        disc_real_source = disc_real_source.mean()\n",
        "        disc_real_class = criterion(disc_real_class, lab_real)\n",
        "\n",
        "        gradient_penalty = calc_gradient_penalty( discriminator, img_real, img_syn)\n",
        "\n",
        "        disc_loss = disc_fake_source - disc_real_source + disc_fake_class + disc_real_class + gradient_penalty\n",
        "        disc_loss.backward()\n",
        "        optim_d.step()\n",
        "\n",
        "        gen_losses.update(gen_loss.item())\n",
        "        disc_losses.update(disc_loss.item())\n",
        "        top1.update(acc1.item())\n",
        "        top5.update(acc5.item())\n",
        "\n",
        "        if (batch_idx + 1) % print_freq == 0:\n",
        "            print('[Train Epoch {} Iter {}] G Loss: {:.3f}({:.3f}) D Loss: {:.3f}({:.3f}) D Acc: {:.3f}({:.3f}) AUC: {:.3f}'.format(\n",
        "                epoch, batch_idx + 1, gen_losses.val, gen_losses.avg, disc_losses.val, disc_losses.avg, top1.val, top1.avg, auc)\n",
        "            )\n",
        "\n",
        "\n",
        "def train_match_model(model, optim_model, trainloader, criterion, aug_rand):\n",
        "    '''The training function for the match model\n",
        "    '''\n",
        "    for batch_idx, (img, lab) in enumerate(trainloader):\n",
        "        if batch_idx == epochs_match_train:\n",
        "            break\n",
        "\n",
        "        img = img.colabcuda()\n",
        "        lab = lab.colabcuda()\n",
        "\n",
        "        output = model(aug_rand(img))\n",
        "        loss = criterion(output, lab)\n",
        "\n",
        "        optim_model.zero_grad()\n",
        "        loss.backward()\n",
        "        optim_model.step()\n",
        "\n",
        "\n",
        "def test(model, testloader, criterion):\n",
        "    '''Calculate accuracy\n",
        "    '''\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    for batch_idx, (img, lab) in enumerate(testloader):\n",
        "        img = img.colabcuda()\n",
        "        lab = lab.colabcuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "        loss = criterion(output, lab)\n",
        "        acc1, acc5 = accuracy(output.data, lab, topk=(1, 5))\n",
        "        losses.update(loss.item(), output.shape[0])\n",
        "        top1.update(acc1.item(), output.shape[0])\n",
        "        top5.update(acc5.item(), output.shape[0])\n",
        "\n",
        "    return top1.avg, top5.avg, losses.avg\n",
        "\n",
        "\n",
        "def validate(generator, testloader, criterion, aug_rand):\n",
        "    '''Validate the generator performance\n",
        "    '''\n",
        "    all_best_top1 = []\n",
        "    all_best_top5 = []\n",
        "    for e_model in eval_model:\n",
        "        print('Evaluating {}'.format(e_model))\n",
        "        model = define_model( num_classes, e_model).colabcuda()\n",
        "        model.train()\n",
        "        optim_model = torch.optim.SGD(model.parameters(), eval_lr, momentum=momentum,\n",
        "                                      weight_decay=weight_decay)\n",
        "\n",
        "        generator.eval()\n",
        "        losses = AverageMeter()\n",
        "        top1 = AverageMeter()\n",
        "        top5 = AverageMeter()\n",
        "        best_top1 = 0.0\n",
        "        best_top5 = 0.0\n",
        "        for epoch_idx in range(epochs_eval):\n",
        "            for batch_idx in range(10 * ipc // batch_size + 1):\n",
        "                # obtain pseudo samples with the generator\n",
        "                lab_syn = torch.randint(num_classes, (batch_size,))\n",
        "                noise = torch.normal(0, 1, (batch_size, dim_noise))\n",
        "                lab_onehot = torch.zeros((batch_size, num_classes))\n",
        "                lab_onehot[torch.arange(batch_size), lab_syn] = 1\n",
        "                noise[torch.arange(batch_size), :num_classes] = lab_onehot[torch.arange(batch_size)]\n",
        "                noise = noise.colabcuda()\n",
        "                lab_syn = lab_syn.colabcuda()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    img_syn = generator(noise)\n",
        "                    img_syn = aug_rand((img_syn + 1.0) / 2.0)\n",
        "\n",
        "                if np.random.rand(1) < mix_p and mixup_net == 'cut':\n",
        "                    lam = np.random.beta(beta, beta)\n",
        "                    rand_index = torch.randperm(len(img_syn)).colabcuda()\n",
        "\n",
        "                    lab_syn_b = lab_syn[rand_index]\n",
        "                    bbx1, bby1, bbx2, bby2 = rand_bbox(img_syn.size(), lam)\n",
        "                    img_syn[:, :, bbx1:bbx2, bby1:bby2] = img_syn[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "                    ratio = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img_syn.size()[-1] * img_syn.size()[-2]))\n",
        "\n",
        "                    output = model(img_syn)\n",
        "                    loss = criterion(output, lab_syn) * ratio + criterion(output, lab_syn_b) * (1. - ratio)\n",
        "                else:\n",
        "                    output = model(img_syn)\n",
        "                    loss = criterion(output, lab_syn)\n",
        "\n",
        "                acc1, acc5 = accuracy(output.data, lab_syn, topk=(1, 5))\n",
        "\n",
        "                losses.update(loss.item(), img_syn.shape[0])\n",
        "                top1.update(acc1.item(), img_syn.shape[0])\n",
        "                top5.update(acc5.item(), img_syn.shape[0])\n",
        "\n",
        "                optim_model.zero_grad()\n",
        "                loss.backward()\n",
        "                optim_model.step()\n",
        "\n",
        "            if (epoch_idx + 1) % test_interval == 0:\n",
        "                test_top1, test_top5, test_loss = test( model, testloader, criterion)\n",
        "                print('[Test Epoch {}] Top1: {:.3f} Top5: {:.3f}'.format(epoch_idx + 1, test_top1, test_top5))\n",
        "                if test_top1 > best_top1:\n",
        "                    best_top1 = test_top1\n",
        "                    best_top5 = test_top5\n",
        "\n",
        "        all_best_top1.append(best_top1)\n",
        "        all_best_top5.append(best_top5)\n",
        "\n",
        "    return all_best_top1, all_best_top5\n",
        "\n",
        "\n",
        "#noise_multiplier=1.07\n",
        "\n",
        "def dp_conv_hook(module, grad_input, grad_output):\n",
        "    '''\n",
        "    gradient modification + noise hook\n",
        "\n",
        "    :param module:\n",
        "    :param grad_input:\n",
        "    :param grad_output:\n",
        "    :return:\n",
        "    '''\n",
        "    CLIP_BOUND = 1.\n",
        "    SENSITIVITY = 2.\n",
        "    noise_multiplier=1.07\n",
        "\n",
        "    #global noise_multiplier\n",
        "    ### get grad wrt. input (image)\n",
        "    grad_wrt_image = grad_input[0]\n",
        "    grad_input_shape = grad_wrt_image.size()\n",
        "    batchsize = grad_input_shape[0]\n",
        "    clip_bound_ = CLIP_BOUND / batchsize\n",
        "\n",
        "    grad_wrt_image = grad_wrt_image.view(batchsize, -1)\n",
        "    grad_input_norm = torch.norm(grad_wrt_image, p=2, dim=1)\n",
        "\n",
        "    ### clip\n",
        "    clip_coef = clip_bound_ / (grad_input_norm + 1e-10)\n",
        "    clip_coef = torch.min(clip_coef, torch.ones_like(clip_coef))\n",
        "    clip_coef = clip_coef.unsqueeze(-1)\n",
        "    grad_wrt_image = clip_coef * grad_wrt_image\n",
        "\n",
        "    ### add noise\n",
        "    noise = clip_bound_ * noise_multiplier * SENSITIVITY * torch.randn_like(grad_wrt_image)\n",
        "    grad_wrt_image = grad_wrt_image + noise\n",
        "    grad_input_new = [grad_wrt_image.view(grad_input_shape)]\n",
        "    for i in range(len(grad_input) - 1):\n",
        "        grad_input_new.append(grad_input[i + 1])\n",
        "    return tuple(grad_input_new)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "gpu=colab.connect_sys(\"v100\")\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(drive.mount(output_dir))\n",
        "output_dir = output_dir + tag\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(drive.mount(output_dir))\n",
        "if not os.path.exists(drive.mount(output_dir) + '/outputs'):\n",
        "    os.makedirs(drive.mount(output_dir) + '/outputs')\n",
        "\n",
        "if not os.path.exists(drive.mount(logs_dir)):\n",
        "    os.makedirs(drive.mount(logs_dir))\n",
        "logs_dir = logs_dir + tag\n",
        "if not os.path.exists(drive.mount(logs_dir)):\n",
        "    os.makedirs(drive.mount(logs_dir))\n",
        "sys.stdout = Logger(os.path.join(logs_dir, 'logs.txt'))\n",
        "\n",
        "\n",
        "trainloader, testloader = load_data()\n",
        "\n",
        "generator = Generator().colabcuda()\n",
        "discriminator = Discriminator().colabcuda()\n",
        "\n",
        "optim_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
        "optim_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0, 0.9))\n",
        "\n",
        "colab.setsys(\"pro\")\n",
        "model_dict = torch.load(drive.load(weight))\n",
        "generator.load_state_dict(model_dict['generator'])\n",
        "discriminator.load_state_dict(model_dict['discriminator'])\n",
        "optim_g.load_state_dict(model_dict['optim_g'])\n",
        "optim_d.load_state_dict(model_dict['optim_d'])\n",
        "for g in optim_g.param_groups:\n",
        "    g['lr'] = lr\n",
        "for g in optim_d.param_groups:\n",
        "    g['lr'] = lr\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "aug, aug_rand = diffaug()\n",
        "\n",
        "best_top1s = np.zeros((len(eval_model),))\n",
        "best_top5s = np.zeros((len(eval_model),))\n",
        "best_epochs = np.zeros((len(eval_model),))\n",
        "for epoch in range(epochs):\n",
        "    colab.call_sys(\"active\")\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    train(, epoch, generator, discriminator, optim_g, optim_d, trainloader, criterion, aug, aug_rand)\n",
        "    dynamic_hook_function = dp_conv_hook\n",
        "\n",
        "    # save image for visualization\n",
        "    generator.eval()\n",
        "    test_label = torch.tensor(list(range(2)) *10)#*10\n",
        "    #print(test_label)\n",
        "    test_noise = torch.normal(0, 1, (100, 100))\n",
        "    #print(test_noise)\n",
        "    #print(\"hello\")\n",
        "    # noise = torch.randn(batchsize, z_dim).to(device0)\n",
        "    # label = torch.randint(0, NUM_CLASSES, [batchsize]).to(device0)\n",
        "    # noisev = autograd.Variable(noise)\n",
        "    lab_onehot = torch.zeros((100, num_classes))\n",
        "    #print(lab_onehot)\n",
        "    lab_onehot[torch.arange(100), test_label] = 1\n",
        "    test_noise[torch.arange(100), :num_classes] = lab_onehot[torch.arange(100)]\n",
        "    # if epoch==1:\n",
        "    #   print(test_noise)\n",
        "    test_noise = test_noise.colabcuda()\n",
        "    test_img_syn = (generator(test_noise) + 1.0) / 2.0\n",
        "    test_img_syn = make_grid(test_img_syn, nrow=10)\n",
        "    generator.train()\n",
        "\n",
        "    if (epoch + 1) % eval_interval == 0:\n",
        "        top1s, top5s = validate(, generator, testloader, criterion, aug_rand)\n",
        "        for e_idx, e_model in enumerate(eval_model):\n",
        "            if top1s[e_idx] > best_top1s[e_idx]:\n",
        "                best_top1s[e_idx] = top1s[e_idx]\n",
        "                best_top5s[e_idx] = top5s[e_idx]\n",
        "                best_epochs[e_idx] = epoch\n",
        "\n",
        "                model_dict = {'generator': generator.state_dict(),\n",
        "                              'discriminator': discriminator.state_dict(),\n",
        "                              'optim_g': optim_g.state_dict(),\n",
        "                              'optim_d': optim_d.state_dict()}\n",
        "                torch.save(\n",
        "                    model_dict,\n",
        "                    os.path.join(drive.mount(output_dir), 'model_dict_{}.pth'.format(e_model)))\n",
        "                print('Save model for {}'.format(e_model))\n",
        "\n",
        "            print('Current Best Epoch for {}: {}, Top1: {:.3f}, Top5: {:.3f}'.format(e_model, best_epochs[e_idx], best_top1s[e_idx], best_top5s[e_idx]))"
      ],
      "metadata": {
        "id": "vJHDdfgtBPme"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}